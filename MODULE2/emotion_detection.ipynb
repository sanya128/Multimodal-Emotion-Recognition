{"cells":[{"cell_type":"code","execution_count":6,"id":"738dc1ce","metadata":{"id":"738dc1ce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740647449544,"user_tz":-330,"elapsed":2055,"user":{"displayName":"VIRENDRA KUMAR MEGHWAL","userId":"10987795721038852225"}},"outputId":"9e8dfdca-5be5-4a34-f46f-03d912935acf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","emotion_detection.ipynb  fer.h5  haarcascade_frontalface_default.xml  image_emotion.npy\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive/\")\n","import os\n","os.chdir(\"/content/gdrive/My Drive/MultimodalEmotion/MODULE2\")\n","!ls"]},{"cell_type":"code","source":[],"metadata":{"id":"LGs-VYk4qZ5Q","executionInfo":{"status":"ok","timestamp":1740647449559,"user_tz":-330,"elapsed":3,"user":{"displayName":"VIRENDRA KUMAR MEGHWAL","userId":"10987795721038852225"}}},"id":"LGs-VYk4qZ5Q","execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"id":"9e6fc377","metadata":{"id":"9e6fc377","executionInfo":{"status":"ok","timestamp":1740647449573,"user_tz":-330,"elapsed":12,"user":{"displayName":"VIRENDRA KUMAR MEGHWAL","userId":"10987795721038852225"}}},"outputs":[],"source":["import cv2\n","from keras.models import load_model\n","import numpy as np"]},{"cell_type":"code","execution_count":9,"id":"40a52107","metadata":{"id":"40a52107","colab":{"base_uri":"https://localhost:8080/","height":362},"executionInfo":{"status":"error","timestamp":1740647519137,"user_tz":-330,"elapsed":819,"user":{"displayName":"VIRENDRA KUMAR MEGHWAL","userId":"10987795721038852225"}},"outputId":"c9a64273-7998-4624-8173-5b8b6ce57a4f"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"No model config found in the file at fer_model.h5.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-fb006b361a9d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the pre-trained emotion detection model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0memotion_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fer_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Read the input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0;34mf\"No model config found in the file at {filepath}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: No model config found in the file at fer_model.h5."]}],"source":["# Load the pre-trained face detection cascade classifier\n","face_cascade = cv2.CascadeClassifier('../haarcascade_frontalface_default.xml')\n","\n","# Load the pre-trained emotion detection model\n","emotion_model = load_model('fer_model.h5')\n","\n","# Read the input image\n","img = cv2.imread('happy.jpeg')\n","\n","# Convert the image to grayscale\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","# Detect faces in the image\n","faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))"]},{"cell_type":"code","execution_count":null,"id":"14e69746","metadata":{"id":"14e69746","executionInfo":{"status":"aborted","timestamp":1740647449693,"user_tz":-330,"elapsed":2,"user":{"displayName":"VIRENDRA KUMAR MEGHWAL","userId":"10987795721038852225"}}},"outputs":[],"source":["# Loop through each face in the image\n","for (x, y, w, h) in faces:\n","    # Extract the face region of interest\n","    roi_gray = gray[y:y+h, x:x+w]\n","\n","    # Resize the ROI to match the input shape of the emotion detection model\n","    roi_gray = cv2.resize(roi_gray, (48, 48))\n","\n","    # Normalize the pixel values of the ROI to be between 0 and 1\n","    roi_gray = roi_gray / 255.0\n","\n","    # Make a prediction on the ROI using the emotion detection model\n","    prediction = emotion_model.predict(roi_gray.reshape(1, 48, 48, 1))\n","\n","    np.save('image_emotion.npy', prediction)\n","\n","    # Get the emotion label with the highest probability\n","    emotion_label = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'][np.argmax(prediction)]\n","\n","    print(prediction)\n","\n","    # Draw a rectangle around the face and label the detected emotion\n","    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","    cv2.putText(img, emotion_label, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)"]},{"cell_type":"code","execution_count":null,"id":"17fbe7c5","metadata":{"id":"17fbe7c5","executionInfo":{"status":"aborted","timestamp":1740647449705,"user_tz":-330,"elapsed":1,"user":{"displayName":"VIRENDRA KUMAR MEGHWAL","userId":"10987795721038852225"}}},"outputs":[],"source":["#resize the image to the screen size\n","screen_res = 1920, 1080\n","img = cv2.resize(img, screen_res)"]},{"cell_type":"code","execution_count":null,"id":"b9bd0b19","metadata":{"id":"b9bd0b19","executionInfo":{"status":"aborted","timestamp":1740647449708,"user_tz":-330,"elapsed":2528,"user":{"displayName":"VIRENDRA KUMAR MEGHWAL","userId":"10987795721038852225"}}},"outputs":[],"source":["# Display the output image\n","cv2.imshow('Emotion Detection', img)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"id":"f51d04c6","metadata":{"id":"f51d04c6","executionInfo":{"status":"aborted","timestamp":1740647449710,"user_tz":-330,"elapsed":2528,"user":{"displayName":"VIRENDRA KUMAR MEGHWAL","userId":"10987795721038852225"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}